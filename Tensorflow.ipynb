{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import Tensorflow\r\n",
    "import tensorflow as tf\r\n",
    "print(tf.__version__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Her bir tensörün veri tipi ve şekli vardır.\r\n",
    "## Veri tipleri: float32, int32, string, others.\r\n",
    "## Şekli: Basitce verinin boyutu denebilir.\r\n",
    "\r\n",
    "# Farklı tensör çeşitlerinin oluşturulmasına örnekler\r\n",
    "\r\n",
    "string = tf.Variable('Bu bir dizidir.', tf.string)\r\n",
    "number = tf.Variable(297, tf.int16)\r\n",
    "flaot = tf.Variable(3.16, tf.float64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Rank/Degree Tensörde yer alan boyutların sayısı anlamına gelir.\r\n",
    "\r\n",
    "print('string değişkeninin boyutu: ', tf.rank(string)) ## 0 boyutlu yani skaler değişken.\r\n",
    "\r\n",
    "rank1_tensor = tf.Variable(['Test'], tf.string)\r\n",
    "rank2_tensor = tf.Variable([['test','ok'],['test','yes']], tf.string)\r\n",
    "\r\n",
    "print('rank1_tensor boyutu: ', tf.rank(rank1_tensor)) ## 1 boyutlu yani vektör.\r\n",
    "print('rank_2tensor boyutu: ', tf.rank(rank2_tensor)) ## 2 boyutlu yani matrix."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Shape tensör içinde her boyutta bize kaç eleman olduğunu söyler.\r\n",
    "\r\n",
    "print('number değişkeninin şekli(shape)', number.shape) ## Sıfır boyutlu yani skaler\r\n",
    "print('rank1_tensörünün şekli(shape)', rank1_tensor.shape) ## Bir boyutlu bir elemanlı\r\n",
    "print('rank2_tensörünün şekli(shape)', rank2_tensor.shape) ## İki boyutlu iki elemanlı (Liste içersinde iki liste her listede 2 eleman var.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Tensörlerde Şekil(Reshape) değiştirme\r\n",
    "\r\n",
    "tensor1 = tf.ones([1, 2, 3]) ## 1 lerden oluşan bir tensör yani rank = 3, shape = [1, 2, 3] (Liste içersinde bir liste o listenin içersinde iki liste her listede 3 eleman)\r\n",
    "tensor2 = tf.reshape(tensor1, [2, 3, 1]) ## (Liste içersinde iki liste her iki liste içersinde 3 liste her 3 üç liste içersinde 1 eleman) \r\n",
    "tensor3 = tf.reshape(tensor2, [3, -1]) ## (Liste içersinde 3 liste bu listelerin içinde 2 şer eleman) tensor2 toplam 6 elemanlı bu elemanları 3 listeye 2 şer dağıtılmış hali \r\n",
    "## Tensor 3 deki -1 her listnin içersinde kaç eleman olduğu hesaplar yani toplam 6 elemanlı tensor2 yi tensor3 e çevirirken 6 elemanı 2 şerli olarak 3 listeye sığdıraçağını"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Tensör çeşitleri\r\n",
    "## En çok kullanılan tensör çeşitleri:\r\n",
    "# Variable\r\n",
    "# Constant\r\n",
    "# Placeholder\r\n",
    "# SparseTensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Example\r\n",
    "\r\n",
    "tensor = tf.zeros([5,5,5,5]) ## 1 listenin içerisinde 5 liste bu 5 listenin her birinin içerisinde 5 er liste bu listelerin içersinde 5 er liste bu 5 er listelerin içersinde 5 er eleman\r\n",
    "## Toplamda 5 * 5 * 5 * 5 = 625 eleman\r\n",
    "tensor = tf.reshape(tensor, [625]) ## Bir nevi flatten işlemi 625 elemanlı bir liste yani vektor 1 boyutlu\r\n",
    "tensor = tf.reshape(tensor, [125, -1]) ## Bir liste içerisinde 125 liste her liste içersinde 625 / 125 tane eleman\r\n",
    "tensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from six.moves import urllib\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow.compat.v2.feature_column as fc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\r\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\r\n",
    "\r\n",
    "y_train = df_train.pop('survived')\r\n",
    "y_eval = df_test.pop('survived')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df_train.loc[0], y_train.loc[0]) ## .loc 0.satır"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df_train.describe(), end='\\n\\n')\r\n",
    "print('mean of age: ', df_train.describe().mean().age) ## OR df_train.describe().mean['age]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.shape ## 627 satır ve 9 sütündan oluşan bir dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.age.hist(bins= 20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.sex.value_counts().plot(kind= 'bar')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train['class'].value_counts().plot(kind= 'bar')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.concat([df_train, y_train], axis= 1).groupby('sex')['survived'].mean().plot(kind= 'bar').set_xlabel(r'% survive')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pandas.api.types import is_string_dtype\r\n",
    "from pandas.api.types import is_numeric_dtype\r\n",
    "\r\n",
    "feature_columns = []\r\n",
    "\r\n",
    "for feature_name, Columns in df_train.items():\r\n",
    "    if is_string_dtype(Columns):\r\n",
    "        vocabulary = df_train[feature_name].unique()\r\n",
    "        feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\r\n",
    "    else:\r\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_input_fn(df, label, num_epochs= 10, shuffle= True, batch_size= 32):\r\n",
    "    def input_func():\r\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(df), label))\r\n",
    "        if shuffle:\r\n",
    "            ds = ds.shuffle(1000)\r\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\r\n",
    "        return ds\r\n",
    "    return input_func        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train_input_fn = make_input_fn(df_train, y_train)\r\n",
    "df_test_input_fn = make_input_fn(df_test, y_eval, num_epochs= 1, shuffle= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for feature_batch, label_batch in df_train_input_fn().take(1):\r\n",
    "  print('Some feature keys:', list(feature_batch.keys()))\r\n",
    "  print()\r\n",
    "  print('A batch of class:', feature_batch['sex'].numpy())\r\n",
    "  print()\r\n",
    "  print('A batch of Labels:', label_batch.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "age_column = feature_columns[1]\r\n",
    "tf.keras.layers.DenseFeatures([age_column])(feature_batch).numpy()  ## tf.keras.layers.DenseFeatures katmanını kullanarak belirli bir özellik sütununun sonucunu inceleyebilirsiniz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sex_column = feature_columns[0]\r\n",
    "tf.keras.layers.DenseFeatures([tf.feature_column.indicator_column(sex_column)])(feature_batch).numpy() ## DenseFeatures yalnızca yoğun tensörleri kabul eder, kategorik bir sütunu incelemek için önce bunu bir gösterge sütununa dönüştürmeniz gerekir:"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "\r\n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\r\n",
    "linear_est.train(df_train_input_fn)\r\n",
    "result = linear_est.evaluate(df_test_input_fn)\r\n",
    "\r\n",
    "clear_output()\r\n",
    "print(result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = list(linear_est.predict(df_test_input_fn))\r\n",
    "clear_output()\r\n",
    "print(df_test.loc[0], y_eval[0])\r\n",
    "print(result[0]['probabilities'][1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probs = pd.Series([pred['probabilities'][1] for pred in result])\r\n",
    "probs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_curve\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "\r\n",
    "fpr, tpr, _ = roc_curve(y_eval, probs)\r\n",
    "plt.plot(fpr, tpr)\r\n",
    "plt.title('ROC curve')\r\n",
    "plt.xlabel('false positive rate')\r\n",
    "plt.ylabel('true positive rate')\r\n",
    "plt.xlim(0,)\r\n",
    "plt.ylim(0,)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\r\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\r\n",
    "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\r\n",
    "\r\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\r\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "train_y = train.pop('Species')\r\n",
    "test_y = test.pop('Species')\r\n",
    "\r\n",
    "# The label column has now been removed from the features.\r\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\r\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\r\n",
    "    # Convert the inputs to a Dataset.\r\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n",
    "\r\n",
    "    # Shuffle and repeat if you are in training mode.\r\n",
    "    if training:\r\n",
    "        dataset = dataset.shuffle(1000).repeat()\r\n",
    "\r\n",
    "    return dataset.batch(batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# Feature columns describe how to use the input.\r\n",
    "my_feature_columns = []\r\n",
    "for key in train.keys():\r\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\r\n",
    "classifier = tf.estimator.DNNClassifier(\r\n",
    "    feature_columns=my_feature_columns,\r\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\r\n",
    "    hidden_units=[30, 10],\r\n",
    "    # The model must choose between 3 classes.\r\n",
    "    n_classes=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Madao\\AppData\\Local\\Temp\\tmpmx8bac6m\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Madao\\\\AppData\\\\Local\\\\Temp\\\\tmpmx8bac6m', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# Train the Model.\r\n",
    "classifier.train(\r\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\r\n",
    "    steps=5000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Madao\\AppData\\Local\\Temp\\tmpmx8bac6m\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.3938713, step = 0\n",
      "INFO:tensorflow:global_step/sec: 561.67\n",
      "INFO:tensorflow:loss = 1.0097805, step = 100 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.057\n",
      "INFO:tensorflow:loss = 0.9494438, step = 200 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.815\n",
      "INFO:tensorflow:loss = 0.9166491, step = 300 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.083\n",
      "INFO:tensorflow:loss = 0.8817495, step = 400 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.252\n",
      "INFO:tensorflow:loss = 0.8602422, step = 500 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.147\n",
      "INFO:tensorflow:loss = 0.83463895, step = 600 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.818\n",
      "INFO:tensorflow:loss = 0.80970085, step = 700 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.021\n",
      "INFO:tensorflow:loss = 0.8058013, step = 800 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.667\n",
      "INFO:tensorflow:loss = 0.7853375, step = 900 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.75855756, step = 1000 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.482\n",
      "INFO:tensorflow:loss = 0.7552885, step = 1100 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.021\n",
      "INFO:tensorflow:loss = 0.72950965, step = 1200 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.821\n",
      "INFO:tensorflow:loss = 0.7078006, step = 1300 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.227\n",
      "INFO:tensorflow:loss = 0.710643, step = 1400 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.6928103, step = 1500 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.271\n",
      "INFO:tensorflow:loss = 0.68489015, step = 1600 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.831\n",
      "INFO:tensorflow:loss = 0.66247225, step = 1700 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.824\n",
      "INFO:tensorflow:loss = 0.64613163, step = 1800 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.818\n",
      "INFO:tensorflow:loss = 0.6560153, step = 1900 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.818\n",
      "INFO:tensorflow:loss = 0.6427107, step = 2000 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.491\n",
      "INFO:tensorflow:loss = 0.6280359, step = 2100 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.149\n",
      "INFO:tensorflow:loss = 0.61229736, step = 2200 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.60854673, step = 2300 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.273\n",
      "INFO:tensorflow:loss = 0.59080094, step = 2400 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.252\n",
      "INFO:tensorflow:loss = 0.58676195, step = 2500 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.832\n",
      "INFO:tensorflow:loss = 0.58151007, step = 2600 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.815\n",
      "INFO:tensorflow:loss = 0.57254374, step = 2700 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.487\n",
      "INFO:tensorflow:loss = 0.5553849, step = 2800 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.5630599, step = 2900 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.5512577, step = 3000 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.26\n",
      "INFO:tensorflow:loss = 0.5547527, step = 3100 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 812.829\n",
      "INFO:tensorflow:loss = 0.52751905, step = 3200 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.257\n",
      "INFO:tensorflow:loss = 0.54021966, step = 3300 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.268\n",
      "INFO:tensorflow:loss = 0.53013754, step = 3400 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.493\n",
      "INFO:tensorflow:loss = 0.53675306, step = 3500 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.5224868, step = 3600 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.267\n",
      "INFO:tensorflow:loss = 0.5199538, step = 3700 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.273\n",
      "INFO:tensorflow:loss = 0.52160037, step = 3800 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.148\n",
      "INFO:tensorflow:loss = 0.5113, step = 3900 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.49980175, step = 4000 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.15\n",
      "INFO:tensorflow:loss = 0.49800736, step = 4100 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.142\n",
      "INFO:tensorflow:loss = 0.48634535, step = 4200 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.264\n",
      "INFO:tensorflow:loss = 0.48359382, step = 4300 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.146\n",
      "INFO:tensorflow:loss = 0.46938717, step = 4400 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.144\n",
      "INFO:tensorflow:loss = 0.48060977, step = 4500 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.259\n",
      "INFO:tensorflow:loss = 0.47228736, step = 4600 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.145\n",
      "INFO:tensorflow:loss = 0.45775792, step = 4700 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.262\n",
      "INFO:tensorflow:loss = 0.4617322, step = 4800 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.485\n",
      "INFO:tensorflow:loss = 0.47151765, step = 4900 (0.122 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\Madao\\AppData\\Local\\Temp\\tmpmx8bac6m\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.47420853.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x13387d3fc88>"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "eval_result = classifier.evaluate(\r\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\r\n",
    "\r\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-09-04T22:06:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Madao\\AppData\\Local\\Temp\\tmpmx8bac6m\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.18504s\n",
      "INFO:tensorflow:Finished evaluation at 2021-09-04-22:06:21\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.73333335, average_loss = 0.5436447, global_step = 5000, loss = 0.5436447\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\Madao\\AppData\\Local\\Temp\\tmpmx8bac6m\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.733\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# Generate predictions from the model\r\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\r\n",
    "predict_x = {\r\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\r\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\r\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\r\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\r\n",
    "}\r\n",
    "\r\n",
    "def input_fn(features, batch_size=256):\r\n",
    "    \"\"\"An input function for prediction.\"\"\"\r\n",
    "    # Convert the inputs to a Dataset without labels.\r\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\r\n",
    "\r\n",
    "predictions = classifier.predict(\r\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\r\n",
    "    class_id = pred_dict['class_ids'][0]\r\n",
    "    probability = pred_dict['probabilities'][class_id]\r\n",
    "\r\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\r\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Madao\\AppData\\Local\\Temp\\tmpmx8bac6m\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (81.2%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (45.6%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (60.1%), expected \"Virginica\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02b1dde27e87edefdf863d7c5938f5ab14d0dbf5d66335f903d8a417c652c631"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}